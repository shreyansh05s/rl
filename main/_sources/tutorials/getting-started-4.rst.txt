
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorials/getting-started-4.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_tutorials_getting-started-4.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorials_getting-started-4.py:


Get started with logging
========================

**Author**: `Vincent Moens <https://github.com/vmoens>`_

.. _gs_logging:

.. note:: To run this tutorial in a notebook, add an installation cell
  at the beginning containing:

    .. code-block::

        !pip install tensordict
        !pip install torchrl

.. GENERATED FROM PYTHON SOURCE LINES 20-45

The final chapter of this series before we orchestrate everything in a
training script is to learn about logging.

Loggers
-------

Logging is crucial for reporting your results to the outside world and for
you to check that your algorithm is learning properly. TorchRL has several
loggers that interface with custom backends such as
wandb (:class:`~torchrl.record.loggers.wandb.WandbLogger`),
tensorboard (:class:`~torchrl.record.loggers.tensorboard.TensorBoardLogger`) or a lightweight and
portable CSV logger (:class:`~torchrl.record.loggers.csv.CSVLogger`) that you can use
pretty much everywhere.

Loggers are located in the ``torchrl.record`` module and the various classes
can be found in the :ref:`API reference <ref_loggers>`.

We tried to keep the loggers APIs as similar as we could, given the
differences in the underlying backends. While execution of the loggers will
mostly be interchangeable, their instantiation can differ.

Usually, building a logger requires
at least an experiment name and possibly a logging directory and other
hyperparameters.


.. GENERATED FROM PYTHON SOURCE LINES 45-50

.. code-block:: Python


    from torchrl.record import CSVLogger

    logger = CSVLogger(exp_name="my_exp")








.. GENERATED FROM PYTHON SOURCE LINES 51-55

Once the logger is instantiated, the only thing left to do is call the
logging methods! For example, :meth:`~torchrl.record.CSVLogger.log_scalar`
is used in several places across the training examples to log values such as
reward, loss value or time elapsed for executing a piece of code.

.. GENERATED FROM PYTHON SOURCE LINES 55-58

.. code-block:: Python


    logger.log_scalar("my_scalar", 0.4)








.. GENERATED FROM PYTHON SOURCE LINES 59-77

Recording videos
----------------

Finally, it can come in handy to record videos of a simulator. Some
environments (e.g., Atari games) are already rendered as images whereas
others require you to create them as such. Fortunately, in most common cases,
rendering and recording videos isn't too difficult.

Let's first see how we can create a Gym environment that outputs images
alongside its observations. :class:`~torchrl.envs.GymEnv` accept two keywords
for this purpose:
- ``from_pixels=True`` will make the env ``step`` function
write a ``"pixels"`` entry containing the images corresponding to your
observations, and

- ``pixels_only=False`` will indicate that you want the
observations to be returned as well.


.. GENERATED FROM PYTHON SOURCE LINES 77-86

.. code-block:: Python


    from torchrl.envs import GymEnv

    env = GymEnv("CartPole-v1", from_pixels=True, pixels_only=False)

    print(env.rollout(max_steps=3))

    from torchrl.envs import TransformedEnv





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    TensorDict(
        fields={
            action: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.int64, is_shared=False),
            done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),
            next: TensorDict(
                fields={
                    done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),
                    observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
                    pixels: Tensor(shape=torch.Size([3, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),
                    reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),
                    terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),
                    truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},
                batch_size=torch.Size([3]),
                device=None,
                is_shared=False),
            observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
            pixels: Tensor(shape=torch.Size([3, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),
            terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),
            truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},
        batch_size=torch.Size([3]),
        device=None,
        is_shared=False)




.. GENERATED FROM PYTHON SOURCE LINES 87-92

We now have built an environment that renders images with its observations.
To record videos, we will need to combine that environment with a recorder
and the logger (the logger providing the backend to save the video).
This will happen within a transformed environment, like the one we saw in
the :ref:`first tutorial <gs_env_ted>`.

.. GENERATED FROM PYTHON SOURCE LINES 92-98

.. code-block:: Python


    from torchrl.record import VideoRecorder

    recorder = VideoRecorder(logger, tag="my_video")
    record_env = TransformedEnv(env, recorder)








.. GENERATED FROM PYTHON SOURCE LINES 99-102

When running this environment, all the ``"pixels"`` entries will be saved in
a local buffer (i.e. RAM) and dumped in a video on demand (to prevent excessive
RAM usage, you are advised to call this method whenever appropriate!):

.. GENERATED FROM PYTHON SOURCE LINES 102-107

.. code-block:: Python


    rollout = record_env.rollout(max_steps=3)
    # Uncomment this line to save the video on disk:
    # recorder.dump()








.. GENERATED FROM PYTHON SOURCE LINES 108-117

In this specific case, the video format can be chosen when instantiating
the CSVLogger.

(If you want to customise how your video is recorded, have a look at :ref:`our knowledge base <ref_knowledge_base>`.)

This is all we wanted to cover in the getting started tutorial.
You should now be ready to code your
:ref:`first training loop with TorchRL <gs_first_training>`!



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 15.227 seconds)

**Estimated memory usage:**  352 MB


.. _sphx_glr_download_tutorials_getting-started-4.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: getting-started-4.ipynb <getting-started-4.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: getting-started-4.py <getting-started-4.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: getting-started-4.zip <getting-started-4.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
